{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/fytroo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "import Augmentor\n",
    "import easydict\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no argsparse\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    'bs': 64, \n",
    "    'epoch' : 100,\n",
    "    'lr' : 0.05,\n",
    "    'gpu': 0,\n",
    "    'out': 'result',\n",
    "    'resume': '',\n",
    "    'n_in': 32, \n",
    "})\n",
    "try:\n",
    "    __file__.endswith('py')\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Chainer example: MNIST')\n",
    "    parser.add_argument('--batchsize', '-b', dest='bs', type=int, default=args.bs,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=args.epoch,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--learningrate', '-l', dest='lr', type=float, default=args.lr,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--frequency', '-f', type=int, default=-1,\n",
    "                        help='Frequency of taking a snapshot')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=args.gpu,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--out', '-o', default=args.out,\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--resume', '-r', default=args.resume,\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--unit', '-u', dest='n_in', type=int, default=args.n_in,\n",
    "                        help='Number of units')\n",
    "    parser.add_argument('--noplot', dest='plot', action='store_false',\n",
    "                        help='Disable PlotReport extension')\n",
    "    args = parser.parse_args()\n",
    "except:\n",
    "    print('no argsparse')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fytroo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0001.png</td>\n",
       "      <td>flower_images/0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0002.png</td>\n",
       "      <td>flower_images/0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0003.png</td>\n",
       "      <td>flower_images/0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>flower_images/0004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0005.png</td>\n",
       "      <td>flower_images/0005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0006.png</td>\n",
       "      <td>flower_images/0006.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0007.png</td>\n",
       "      <td>flower_images/0007.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0008.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0008.png</td>\n",
       "      <td>flower_images/0008.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0009.png</td>\n",
       "      <td>flower_images/0009.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0010.png</td>\n",
       "      <td>flower_images/0010.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0011.png</td>\n",
       "      <td>flower_images/0011.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0012.png</td>\n",
       "      <td>flower_images/0012.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0013.png</td>\n",
       "      <td>flower_images/0013.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0014.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0014.png</td>\n",
       "      <td>flower_images/0014.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0015.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0015.png</td>\n",
       "      <td>flower_images/0015.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0016.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0016.png</td>\n",
       "      <td>flower_images/0016.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0017.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0017.png</td>\n",
       "      <td>flower_images/0017.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0018.png</td>\n",
       "      <td>flower_images/0018.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0019.png</td>\n",
       "      <td>flower_images/0019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0020.png</td>\n",
       "      <td>flower_images/0020.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0021.png</td>\n",
       "      <td>flower_images/0021.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0022.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0022.png</td>\n",
       "      <td>flower_images/0022.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0023.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0023.png</td>\n",
       "      <td>flower_images/0023.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0024.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0024.png</td>\n",
       "      <td>flower_images/0024.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0025.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0025.png</td>\n",
       "      <td>flower_images/0025.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0026.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0026.png</td>\n",
       "      <td>flower_images/0026.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0027.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0027.png</td>\n",
       "      <td>flower_images/0027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0028.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0028.png</td>\n",
       "      <td>flower_images/0028.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0029.png</td>\n",
       "      <td>flower_images/0029.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0030.png</td>\n",
       "      <td>flower_images/0030.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0181.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0181.png</td>\n",
       "      <td>flower_images/0181.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0182.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0182.png</td>\n",
       "      <td>flower_images/0182.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0183.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0183.png</td>\n",
       "      <td>flower_images/0183.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0184.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0184.png</td>\n",
       "      <td>flower_images/0184.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0185.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0185.png</td>\n",
       "      <td>flower_images/0185.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0186.png</th>\n",
       "      <td>9</td>\n",
       "      <td>0186.png</td>\n",
       "      <td>flower_images/0186.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0187.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0187.png</td>\n",
       "      <td>flower_images/0187.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0188.png</td>\n",
       "      <td>flower_images/0188.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0189.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0189.png</td>\n",
       "      <td>flower_images/0189.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0190.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0190.png</td>\n",
       "      <td>flower_images/0190.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0191.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0191.png</td>\n",
       "      <td>flower_images/0191.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0192.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0192.png</td>\n",
       "      <td>flower_images/0192.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0193.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0193.png</td>\n",
       "      <td>flower_images/0193.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0194.png</th>\n",
       "      <td>9</td>\n",
       "      <td>0194.png</td>\n",
       "      <td>flower_images/0194.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0195.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0195.png</td>\n",
       "      <td>flower_images/0195.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0196.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0196.png</td>\n",
       "      <td>flower_images/0196.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0197.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0197.png</td>\n",
       "      <td>flower_images/0197.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0198.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0198.png</td>\n",
       "      <td>flower_images/0198.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0199.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0199.png</td>\n",
       "      <td>flower_images/0199.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0200.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0200.png</td>\n",
       "      <td>flower_images/0200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0201.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0201.png</td>\n",
       "      <td>flower_images/0201.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0202.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0202.png</td>\n",
       "      <td>flower_images/0202.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0203.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0203.png</td>\n",
       "      <td>flower_images/0203.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0204.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0204.png</td>\n",
       "      <td>flower_images/0204.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0205.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0205.png</td>\n",
       "      <td>flower_images/0205.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0206.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0206.png</td>\n",
       "      <td>flower_images/0206.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0207.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0207.png</td>\n",
       "      <td>flower_images/0207.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0208.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0208.png</td>\n",
       "      <td>flower_images/0208.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0209.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0209.png</td>\n",
       "      <td>flower_images/0209.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0210.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0210.png</td>\n",
       "      <td>flower_images/0210.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label      name                    path\n",
       "file                                             \n",
       "0001.png      0  0001.png  flower_images/0001.png\n",
       "0002.png      0  0002.png  flower_images/0002.png\n",
       "0003.png      2  0003.png  flower_images/0003.png\n",
       "0004.png      0  0004.png  flower_images/0004.png\n",
       "0005.png      0  0005.png  flower_images/0005.png\n",
       "0006.png      1  0006.png  flower_images/0006.png\n",
       "0007.png      6  0007.png  flower_images/0007.png\n",
       "0008.png      0  0008.png  flower_images/0008.png\n",
       "0009.png      0  0009.png  flower_images/0009.png\n",
       "0010.png      0  0010.png  flower_images/0010.png\n",
       "0011.png      0  0011.png  flower_images/0011.png\n",
       "0012.png      0  0012.png  flower_images/0012.png\n",
       "0013.png      0  0013.png  flower_images/0013.png\n",
       "0014.png      7  0014.png  flower_images/0014.png\n",
       "0015.png      7  0015.png  flower_images/0015.png\n",
       "0016.png      1  0016.png  flower_images/0016.png\n",
       "0017.png      0  0017.png  flower_images/0017.png\n",
       "0018.png      0  0018.png  flower_images/0018.png\n",
       "0019.png      6  0019.png  flower_images/0019.png\n",
       "0020.png      0  0020.png  flower_images/0020.png\n",
       "0021.png      2  0021.png  flower_images/0021.png\n",
       "0022.png      4  0022.png  flower_images/0022.png\n",
       "0023.png      7  0023.png  flower_images/0023.png\n",
       "0024.png      4  0024.png  flower_images/0024.png\n",
       "0025.png      5  0025.png  flower_images/0025.png\n",
       "0026.png      6  0026.png  flower_images/0026.png\n",
       "0027.png      2  0027.png  flower_images/0027.png\n",
       "0028.png      5  0028.png  flower_images/0028.png\n",
       "0029.png      6  0029.png  flower_images/0029.png\n",
       "0030.png      6  0030.png  flower_images/0030.png\n",
       "...         ...       ...                     ...\n",
       "0181.png      0  0181.png  flower_images/0181.png\n",
       "0182.png      5  0182.png  flower_images/0182.png\n",
       "0183.png      8  0183.png  flower_images/0183.png\n",
       "0184.png      6  0184.png  flower_images/0184.png\n",
       "0185.png      3  0185.png  flower_images/0185.png\n",
       "0186.png      9  0186.png  flower_images/0186.png\n",
       "0187.png      6  0187.png  flower_images/0187.png\n",
       "0188.png      1  0188.png  flower_images/0188.png\n",
       "0189.png      3  0189.png  flower_images/0189.png\n",
       "0190.png      7  0190.png  flower_images/0190.png\n",
       "0191.png      4  0191.png  flower_images/0191.png\n",
       "0192.png      7  0192.png  flower_images/0192.png\n",
       "0193.png      1  0193.png  flower_images/0193.png\n",
       "0194.png      9  0194.png  flower_images/0194.png\n",
       "0195.png      8  0195.png  flower_images/0195.png\n",
       "0196.png      3  0196.png  flower_images/0196.png\n",
       "0197.png      6  0197.png  flower_images/0197.png\n",
       "0198.png      5  0198.png  flower_images/0198.png\n",
       "0199.png      6  0199.png  flower_images/0199.png\n",
       "0200.png      4  0200.png  flower_images/0200.png\n",
       "0201.png      1  0201.png  flower_images/0201.png\n",
       "0202.png      3  0202.png  flower_images/0202.png\n",
       "0203.png      8  0203.png  flower_images/0203.png\n",
       "0204.png      5  0204.png  flower_images/0204.png\n",
       "0205.png      4  0205.png  flower_images/0205.png\n",
       "0206.png      6  0206.png  flower_images/0206.png\n",
       "0207.png      0  0207.png  flower_images/0207.png\n",
       "0208.png      4  0208.png  flower_images/0208.png\n",
       "0209.png      6  0209.png  flower_images/0209.png\n",
       "0210.png      1  0210.png  flower_images/0210.png\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'flower_images'\n",
    "df  = pd.DataFrame.from_csv(os.path.join(dataset_dir,'flower_labels.csv'))\n",
    "\n",
    "df['name'] = df.index\n",
    "df['path'] = dataset_dir + '/' + df['name']\n",
    "\n",
    "n_label = df.label.drop_duplicates().count()\n",
    "n_label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fromdf(dataframe, resize=(96,96)):\n",
    "    if type(resize) is int:\n",
    "        resize = (resize, resize)\n",
    "    \n",
    "    df = dataframe\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        y = row['label']\n",
    "        f = row['path']\n",
    "\n",
    "        img = Image.open(f).resize(resize, Image.LANCZOS)\n",
    "        img = img.convert('RGB')\n",
    "        x = np.array(img)\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = utils.train_test_split_df(df, test_size=0.1)\n",
    "x_train, y_train = load_fromdf(df_train, resize=args.n_in)\n",
    "x_test, y_test = load_fromdf(df_test, resize=args.n_in)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fire(chainer.Chain):\n",
    "    def __init__(self, n_in=None, n_out=32):\n",
    "        super(Fire, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(n_in, 32, 3)\n",
    "            self.conv2 = L.Convolution2D(None, n_out, 3)\n",
    "            self.bn = L.BatchNormalization(32)\n",
    "            self.bn2 = L.BatchNormalization(32)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self, n_in=32, n_out=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 16, 3)\n",
    "            self.fire1 = Fire(None, 32)\n",
    "            self.fire2 = Fire(None, 64)\n",
    "            self.fc = L.Linear(None, n_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.fire1(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.fire2(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L.Classifier(LeNet(args.n_in, n_label),\n",
    "                    lossfun=F.softmax_cross_entropy,\n",
    "                    accfun=F.accuracy)\n",
    "xp = np\n",
    "if args.gpu >= 0:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "    chainer.cuda.get_device_from_id(args.gpu).use()\n",
    "    model.to_gpu()  # Copy the model to the GPU\n",
    "optimizer = chainer.optimizers.MomentumSGD(args.lr)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Augmentor.Pipeline()\n",
    "p.flip_left_right(probability=0.5)\n",
    "p.flip_top_bottom(probability=0.5)\n",
    "g = p.keras_generator_from_array(x_train, y_train, batch_size=args.bs)\n",
    "g = ((\n",
    "    xp.array(np.swapaxes((x/255.), 1, 3)).astype(np.float32),\n",
    "    xp.array(y.astype(np.int8))\n",
    "    ) for (x,y) in g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chainer.trainingを使わず，訓練ループをかく\n",
    "chainer.trainingでは，自前のデータのイテレータを使うことができないため．\n",
    "Augmentorを使いたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(step=None):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    n_data = 0\n",
    "    n_train = len(y_train)\n",
    "    for _ in range(n_train//args.bs):\n",
    "        xs, ts = next(g) \n",
    "        x = chainer.Variable(xs)\n",
    "        t = chainer.Variable(ts)\n",
    "        optimizer.update(model, x, t)\n",
    "        loss = model(x,t)\n",
    "        n_data += len(t.data)\n",
    "        total_loss += float(loss.data) * len(t.data)\n",
    "        total_acc += float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "    if step is None:\n",
    "        print('step:{}\\t loss: {:.4f}\\t acc: {:.4f}'.format(step, total_loss/n_data, total_acc/n_data))\n",
    "    else:\n",
    "        print('loss: {:.4f}\\t acc: {:.4f}'.format(total_loss/n_data, total_acc/n_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    xs = xp.array(np.swapaxes((x_test), 1, 3)).astype(np.float32)\n",
    "    ts = xp.array(y_test).astype(np.int8)\n",
    "    x = chainer.Variable(xs)\n",
    "    t = chainer.Variable(ts)\n",
    "    loss = model(x,t)\n",
    "\n",
    "    n_data = len(t.data)\n",
    "    total_loss = float(loss.data) * len(t.data)\n",
    "    total_acc = float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "    print('val_loss: {:.4f}\\t val_acc: {:.4f}'.format(total_loss/n_data, total_acc/n_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0\n",
      "step:None\t loss: 1.6588\t acc: 0.4635\n",
      "val_loss: 2.7110\t val_acc: 0.1000\n",
      "step:1\n",
      "step:None\t loss: 1.4515\t acc: 0.5052\n",
      "val_loss: 3.0060\t val_acc: 0.2000\n",
      "step:2\n",
      "step:None\t loss: 1.7867\t acc: 0.4479\n",
      "val_loss: 4.7153\t val_acc: 0.2000\n",
      "step:3\n",
      "step:None\t loss: 1.6367\t acc: 0.4948\n",
      "val_loss: 3.1951\t val_acc: 0.3000\n",
      "step:4\n",
      "step:None\t loss: 1.5765\t acc: 0.5417\n",
      "val_loss: 3.8950\t val_acc: 0.2000\n",
      "step:5\n",
      "step:None\t loss: 1.5026\t acc: 0.5365\n",
      "val_loss: 3.5863\t val_acc: 0.4000\n",
      "step:6\n",
      "step:None\t loss: 1.2639\t acc: 0.5521\n",
      "val_loss: 2.4490\t val_acc: 0.3000\n",
      "step:7\n",
      "step:None\t loss: 1.1374\t acc: 0.6406\n",
      "val_loss: 4.3937\t val_acc: 0.4000\n",
      "step:8\n",
      "step:None\t loss: 1.1947\t acc: 0.5990\n",
      "val_loss: 3.2423\t val_acc: 0.3000\n",
      "step:9\n",
      "step:None\t loss: 1.0357\t acc: 0.6250\n",
      "val_loss: 2.4293\t val_acc: 0.2000\n",
      "step:10\n",
      "step:None\t loss: 0.9876\t acc: 0.6615\n",
      "val_loss: 3.7288\t val_acc: 0.2000\n",
      "step:11\n",
      "step:None\t loss: 0.9733\t acc: 0.6458\n",
      "val_loss: 2.7362\t val_acc: 0.4000\n",
      "step:12\n",
      "step:None\t loss: 1.1165\t acc: 0.6146\n",
      "val_loss: 1.9590\t val_acc: 0.3000\n",
      "step:13\n",
      "step:None\t loss: 0.8135\t acc: 0.7188\n",
      "val_loss: 1.6055\t val_acc: 0.6000\n",
      "step:14\n",
      "step:None\t loss: 0.7429\t acc: 0.7292\n",
      "val_loss: 3.3168\t val_acc: 0.4000\n",
      "step:15\n",
      "step:None\t loss: 0.7777\t acc: 0.7552\n",
      "val_loss: 3.5343\t val_acc: 0.4000\n",
      "step:16\n",
      "step:None\t loss: 0.7032\t acc: 0.7396\n",
      "val_loss: 3.5015\t val_acc: 0.5000\n",
      "step:17\n",
      "step:None\t loss: 0.6652\t acc: 0.7604\n",
      "val_loss: 3.7916\t val_acc: 0.3000\n",
      "step:18\n",
      "step:None\t loss: 0.6325\t acc: 0.7760\n",
      "val_loss: 2.6126\t val_acc: 0.4000\n",
      "step:19\n",
      "step:None\t loss: 0.6427\t acc: 0.7396\n",
      "val_loss: 2.8464\t val_acc: 0.4000\n",
      "step:20\n",
      "step:None\t loss: 0.5630\t acc: 0.7708\n",
      "val_loss: 2.5747\t val_acc: 0.4000\n",
      "step:21\n",
      "step:None\t loss: 0.5505\t acc: 0.7969\n",
      "val_loss: 2.7500\t val_acc: 0.4000\n",
      "step:22\n",
      "step:None\t loss: 0.5649\t acc: 0.7865\n",
      "val_loss: 2.4833\t val_acc: 0.4000\n",
      "step:23\n",
      "step:None\t loss: 0.5592\t acc: 0.7969\n",
      "val_loss: 1.8643\t val_acc: 0.5000\n",
      "step:24\n",
      "step:None\t loss: 0.5380\t acc: 0.7969\n",
      "val_loss: 1.9008\t val_acc: 0.6000\n",
      "step:25\n",
      "step:None\t loss: 0.6543\t acc: 0.7396\n",
      "val_loss: 2.3914\t val_acc: 0.5000\n",
      "step:26\n",
      "step:None\t loss: 0.4706\t acc: 0.8438\n",
      "val_loss: 3.5318\t val_acc: 0.4000\n",
      "step:27\n",
      "step:None\t loss: 0.5528\t acc: 0.7656\n",
      "val_loss: 3.5164\t val_acc: 0.4000\n",
      "step:28\n",
      "step:None\t loss: 0.5666\t acc: 0.8073\n",
      "val_loss: 2.9978\t val_acc: 0.4000\n",
      "step:29\n",
      "step:None\t loss: 0.5328\t acc: 0.8385\n",
      "val_loss: 2.6321\t val_acc: 0.4000\n",
      "step:30\n",
      "step:None\t loss: 0.4813\t acc: 0.8385\n",
      "val_loss: 1.9457\t val_acc: 0.7000\n",
      "step:31\n",
      "step:None\t loss: 0.4410\t acc: 0.8490\n",
      "val_loss: 2.6322\t val_acc: 0.5000\n",
      "step:32\n",
      "step:None\t loss: 0.3899\t acc: 0.8698\n",
      "val_loss: 3.6814\t val_acc: 0.5000\n",
      "step:33\n",
      "step:None\t loss: 0.3995\t acc: 0.8490\n",
      "val_loss: 2.6193\t val_acc: 0.6000\n",
      "step:34\n",
      "step:None\t loss: 0.3815\t acc: 0.8698\n",
      "val_loss: 2.3448\t val_acc: 0.4000\n",
      "step:35\n",
      "step:None\t loss: 0.4005\t acc: 0.8385\n",
      "val_loss: 2.7612\t val_acc: 0.5000\n",
      "step:36\n",
      "step:None\t loss: 0.3596\t acc: 0.8698\n",
      "val_loss: 2.6993\t val_acc: 0.5000\n",
      "step:37\n",
      "step:None\t loss: 0.3847\t acc: 0.8646\n",
      "val_loss: 2.9768\t val_acc: 0.6000\n",
      "step:38\n",
      "step:None\t loss: 0.3780\t acc: 0.8750\n",
      "val_loss: 1.8637\t val_acc: 0.5000\n",
      "step:39\n",
      "step:None\t loss: 0.4372\t acc: 0.8542\n",
      "val_loss: 1.4223\t val_acc: 0.5000\n",
      "step:40\n",
      "step:None\t loss: 0.2863\t acc: 0.8854\n",
      "val_loss: 2.6511\t val_acc: 0.4000\n",
      "step:41\n",
      "step:None\t loss: 0.3244\t acc: 0.9010\n",
      "val_loss: 2.1066\t val_acc: 0.6000\n",
      "step:42\n",
      "step:None\t loss: 0.2382\t acc: 0.9115\n",
      "val_loss: 1.6935\t val_acc: 0.5000\n",
      "step:43\n",
      "step:None\t loss: 0.3092\t acc: 0.8958\n",
      "val_loss: 2.3418\t val_acc: 0.4000\n",
      "step:44\n",
      "step:None\t loss: 0.2763\t acc: 0.8802\n",
      "val_loss: 2.8389\t val_acc: 0.4000\n",
      "step:45\n",
      "step:None\t loss: 0.3510\t acc: 0.8750\n",
      "val_loss: 2.6309\t val_acc: 0.4000\n",
      "step:46\n",
      "step:None\t loss: 0.2347\t acc: 0.9323\n",
      "val_loss: 1.9760\t val_acc: 0.5000\n",
      "step:47\n",
      "step:None\t loss: 0.2978\t acc: 0.8906\n",
      "val_loss: 2.0805\t val_acc: 0.4000\n",
      "step:48\n",
      "step:None\t loss: 0.3102\t acc: 0.8750\n",
      "val_loss: 1.4498\t val_acc: 0.6000\n",
      "step:49\n",
      "step:None\t loss: 0.3780\t acc: 0.9010\n",
      "val_loss: 2.7760\t val_acc: 0.5000\n",
      "step:50\n",
      "step:None\t loss: 0.3201\t acc: 0.8854\n",
      "val_loss: 2.8157\t val_acc: 0.4000\n",
      "step:51\n",
      "step:None\t loss: 0.3874\t acc: 0.8698\n",
      "val_loss: 1.9885\t val_acc: 0.5000\n",
      "step:52\n",
      "step:None\t loss: 0.2897\t acc: 0.9010\n",
      "val_loss: 3.5467\t val_acc: 0.5000\n",
      "step:53\n",
      "step:None\t loss: 0.3960\t acc: 0.8854\n",
      "val_loss: 3.1631\t val_acc: 0.5000\n",
      "step:54\n",
      "step:None\t loss: 0.2616\t acc: 0.9115\n",
      "val_loss: 2.4122\t val_acc: 0.5000\n",
      "step:55\n",
      "step:None\t loss: 0.2450\t acc: 0.9167\n",
      "val_loss: 2.0789\t val_acc: 0.4000\n",
      "step:56\n",
      "step:None\t loss: 0.1875\t acc: 0.9375\n",
      "val_loss: 1.4736\t val_acc: 0.5000\n",
      "step:57\n",
      "step:None\t loss: 0.1789\t acc: 0.9167\n",
      "val_loss: 2.0661\t val_acc: 0.5000\n",
      "step:58\n",
      "step:None\t loss: 0.1957\t acc: 0.9323\n",
      "val_loss: 3.0156\t val_acc: 0.4000\n",
      "step:59\n",
      "step:None\t loss: 0.1671\t acc: 0.9375\n",
      "val_loss: 4.2141\t val_acc: 0.4000\n",
      "step:60\n",
      "step:None\t loss: 0.1417\t acc: 0.9531\n",
      "val_loss: 4.5934\t val_acc: 0.5000\n",
      "step:61\n",
      "step:None\t loss: 0.1409\t acc: 0.9635\n",
      "val_loss: 4.4405\t val_acc: 0.5000\n",
      "step:62\n",
      "step:None\t loss: 0.1452\t acc: 0.9635\n",
      "val_loss: 3.5892\t val_acc: 0.6000\n",
      "step:63\n",
      "step:None\t loss: 0.0737\t acc: 0.9896\n",
      "val_loss: 2.4402\t val_acc: 0.6000\n",
      "step:64\n",
      "step:None\t loss: 0.1927\t acc: 0.9427\n",
      "val_loss: 2.7633\t val_acc: 0.5000\n",
      "step:65\n",
      "step:None\t loss: 0.1544\t acc: 0.9427\n",
      "val_loss: 3.3073\t val_acc: 0.4000\n",
      "step:66\n",
      "step:None\t loss: 0.1855\t acc: 0.9427\n",
      "val_loss: 2.5587\t val_acc: 0.5000\n",
      "step:67\n",
      "step:None\t loss: 0.1827\t acc: 0.9427\n",
      "val_loss: 2.8201\t val_acc: 0.5000\n",
      "step:68\n",
      "step:None\t loss: 0.1558\t acc: 0.9583\n",
      "val_loss: 2.5165\t val_acc: 0.6000\n",
      "step:69\n",
      "step:None\t loss: 0.1288\t acc: 0.9740\n",
      "val_loss: 3.7175\t val_acc: 0.6000\n",
      "step:70\n",
      "step:None\t loss: 0.1678\t acc: 0.9375\n",
      "val_loss: 3.3875\t val_acc: 0.6000\n",
      "step:71\n",
      "step:None\t loss: 0.1721\t acc: 0.9583\n",
      "val_loss: 2.7997\t val_acc: 0.5000\n",
      "step:72\n",
      "step:None\t loss: 0.1820\t acc: 0.9427\n",
      "val_loss: 5.7950\t val_acc: 0.5000\n",
      "step:73\n",
      "step:None\t loss: 0.3786\t acc: 0.9219\n",
      "val_loss: 4.4177\t val_acc: 0.5000\n",
      "step:74\n",
      "step:None\t loss: 0.1758\t acc: 0.9323\n",
      "val_loss: 1.5326\t val_acc: 0.6000\n",
      "step:75\n",
      "step:None\t loss: 0.2295\t acc: 0.9219\n",
      "val_loss: 2.5476\t val_acc: 0.5000\n",
      "step:76\n",
      "step:None\t loss: 0.1930\t acc: 0.9427\n",
      "val_loss: 4.5575\t val_acc: 0.4000\n",
      "step:77\n",
      "step:None\t loss: 0.1823\t acc: 0.9167\n",
      "val_loss: 5.4486\t val_acc: 0.4000\n",
      "step:78\n",
      "step:None\t loss: 0.2074\t acc: 0.9479\n",
      "val_loss: 5.6755\t val_acc: 0.4000\n",
      "step:79\n",
      "step:None\t loss: 0.2115\t acc: 0.9271\n",
      "val_loss: 5.5284\t val_acc: 0.3000\n",
      "step:80\n",
      "step:None\t loss: 0.1126\t acc: 0.9792\n",
      "val_loss: 4.7363\t val_acc: 0.5000\n",
      "step:81\n",
      "step:None\t loss: 0.1796\t acc: 0.9323\n",
      "val_loss: 3.3993\t val_acc: 0.4000\n",
      "step:82\n",
      "step:None\t loss: 0.0997\t acc: 0.9635\n",
      "val_loss: 2.5552\t val_acc: 0.5000\n",
      "step:83\n",
      "step:None\t loss: 0.1242\t acc: 0.9583\n",
      "val_loss: 2.7138\t val_acc: 0.5000\n",
      "step:84\n",
      "step:None\t loss: 0.1380\t acc: 0.9427\n",
      "val_loss: 3.3708\t val_acc: 0.5000\n",
      "step:85\n",
      "step:None\t loss: 0.1263\t acc: 0.9531\n",
      "val_loss: 2.9352\t val_acc: 0.6000\n",
      "step:86\n",
      "step:None\t loss: 0.2154\t acc: 0.9219\n",
      "val_loss: 2.8735\t val_acc: 0.6000\n",
      "step:87\n",
      "step:None\t loss: 0.1206\t acc: 0.9740\n",
      "val_loss: 2.2107\t val_acc: 0.7000\n",
      "step:88\n",
      "step:None\t loss: 0.1168\t acc: 0.9583\n",
      "val_loss: 1.4304\t val_acc: 0.7000\n",
      "step:89\n",
      "step:None\t loss: 0.0948\t acc: 0.9740\n",
      "val_loss: 2.8631\t val_acc: 0.7000\n",
      "step:90\n",
      "step:None\t loss: 0.0955\t acc: 0.9583\n",
      "val_loss: 4.8163\t val_acc: 0.6000\n",
      "step:91\n",
      "step:None\t loss: 0.0842\t acc: 0.9740\n",
      "val_loss: 5.4793\t val_acc: 0.6000\n",
      "step:92\n",
      "step:None\t loss: 0.0981\t acc: 0.9740\n",
      "val_loss: 4.6930\t val_acc: 0.5000\n",
      "step:93\n",
      "step:None\t loss: 0.0843\t acc: 0.9792\n",
      "val_loss: 2.8646\t val_acc: 0.6000\n",
      "step:94\n",
      "step:None\t loss: 0.1032\t acc: 0.9688\n",
      "val_loss: 3.2307\t val_acc: 0.5000\n",
      "step:95\n",
      "step:None\t loss: 0.0925\t acc: 0.9688\n",
      "val_loss: 3.7576\t val_acc: 0.5000\n",
      "step:96\n",
      "step:None\t loss: 0.1115\t acc: 0.9635\n",
      "val_loss: 3.9329\t val_acc: 0.5000\n",
      "step:97\n",
      "step:None\t loss: 0.1362\t acc: 0.9583\n",
      "val_loss: 3.3295\t val_acc: 0.6000\n",
      "step:98\n",
      "step:None\t loss: 0.1253\t acc: 0.9531\n",
      "val_loss: 2.9291\t val_acc: 0.6000\n",
      "step:99\n",
      "step:None\t loss: 0.1223\t acc: 0.9531\n",
      "val_loss: 2.7114\t val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for i in range(args.epoch):\n",
    "        print('step:{}'.format(i))\n",
    "        train()\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>main/accuracy</th>\n",
       "      <th>main/loss</th>\n",
       "      <th>validation/main/accuracy</th>\n",
       "      <th>validation/main/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.667732</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.749583</td>\n",
       "      <td>109.704292</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>362.686951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.733289</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>40.793514</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>50.882755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798165</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>25.645660</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>12.118826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863760</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>0.804583</td>\n",
       "      <td>13.677096</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>11.006830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930292</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>4.003510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>51.122948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.994253</td>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>0.825417</td>\n",
       "      <td>8.563640</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15.479998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.058523</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>4.063658</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.898781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.129458</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>4.068286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.421888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.196879</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>1.219726</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>1.158345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.262754</td>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>0.425228</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.328283</td>\n",
       "      <td>11</td>\n",
       "      <td>264</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.330402</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.818427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.394076</td>\n",
       "      <td>12</td>\n",
       "      <td>287</td>\n",
       "      <td>0.902609</td>\n",
       "      <td>0.335407</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>1.305998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.462749</td>\n",
       "      <td>13</td>\n",
       "      <td>311</td>\n",
       "      <td>0.894583</td>\n",
       "      <td>0.328965</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>1.268781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.528512</td>\n",
       "      <td>14</td>\n",
       "      <td>335</td>\n",
       "      <td>0.900417</td>\n",
       "      <td>0.333114</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>1.106040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.593645</td>\n",
       "      <td>15</td>\n",
       "      <td>359</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.319461</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.083554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.659427</td>\n",
       "      <td>16</td>\n",
       "      <td>383</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.306253</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.277474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.726619</td>\n",
       "      <td>17</td>\n",
       "      <td>407</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.319359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.723460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.790965</td>\n",
       "      <td>18</td>\n",
       "      <td>431</td>\n",
       "      <td>0.899167</td>\n",
       "      <td>0.336818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.133966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.855341</td>\n",
       "      <td>19</td>\n",
       "      <td>455</td>\n",
       "      <td>0.904583</td>\n",
       "      <td>0.297849</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.051762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.923634</td>\n",
       "      <td>20</td>\n",
       "      <td>479</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.309263</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>1.087982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elapsed_time  epoch  iteration  main/accuracy   main/loss  \\\n",
       "0       0.667732      1         24       0.749583  109.704292   \n",
       "1       0.733289      2         48       0.827500   40.793514   \n",
       "2       0.798165      3         72       0.817500   25.645660   \n",
       "3       0.863760      4         96       0.804583   13.677096   \n",
       "4       0.930292      5        120       0.822917    4.003510   \n",
       "5       0.994253      6        144       0.825417    8.563640   \n",
       "6       1.058523      7        168       0.826667    4.063658   \n",
       "7       1.129458      8        192       0.791667    4.068286   \n",
       "8       1.196879      9        216       0.836667    1.219726   \n",
       "9       1.262754     10        240       0.888333    0.425228   \n",
       "10      1.328283     11        264       0.895000    0.330402   \n",
       "11      1.394076     12        287       0.902609    0.335407   \n",
       "12      1.462749     13        311       0.894583    0.328965   \n",
       "13      1.528512     14        335       0.900417    0.333114   \n",
       "14      1.593645     15        359       0.904167    0.319461   \n",
       "15      1.659427     16        383       0.902500    0.306253   \n",
       "16      1.726619     17        407       0.897917    0.319359   \n",
       "17      1.790965     18        431       0.899167    0.336818   \n",
       "18      1.855341     19        455       0.904583    0.297849   \n",
       "19      1.923634     20        479       0.903750    0.309263   \n",
       "\n",
       "    validation/main/accuracy  validation/main/loss  \n",
       "0                   0.500000            362.686951  \n",
       "1                   0.500000             50.882755  \n",
       "2                   0.482143             12.118826  \n",
       "3                   0.553571             11.006830  \n",
       "4                   0.500000             51.122948  \n",
       "5                   0.500000             15.479998  \n",
       "6                   0.500000              7.898781  \n",
       "7                   0.500000              6.421888  \n",
       "8                   0.517857              1.158345  \n",
       "9                   0.500000              1.500370  \n",
       "10                  0.571429              0.818427  \n",
       "11                  0.517857              1.305998  \n",
       "12                  0.553571              1.268781  \n",
       "13                  0.553571              1.106040  \n",
       "14                  0.535714              1.083554  \n",
       "15                  0.500000              1.277474  \n",
       "16                  0.500000              1.723460  \n",
       "17                  0.500000              1.133966  \n",
       "18                  0.500000              1.051762  \n",
       "19                  0.517857              1.087982  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.load(open('result/log'))\n",
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU9CLiMScgl5EJOb+Pz7Z4/svG5goAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff194590128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['epoch'], df['main/loss'], color='blue')\n",
    "plt.plot(df['epoch'], df['validation/main/loss'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsYsswAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff19449d9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['epoch'], df['main/accuracy'], color='blue')\n",
    "plt.plot(df['epoch'], df['validation/main/accuracy'], color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
