{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/fytroo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no argsparse\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    'bs': 64, \n",
    "    'epoch' : 100,\n",
    "    'lr' : 0.005,\n",
    "    'gpu': 0,\n",
    "    'out': 'result',\n",
    "    'resume': '',\n",
    "})\n",
    "try:\n",
    "    __file__.endswith('py')\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Chainer example: MNIST')\n",
    "    parser.add_argument('--batchsize', '-b', dest='bs', type=int, default=args.bs,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=args.epoch,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--learningrate', '-l', dest='lr', type=float, default=args.lr,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--frequency', '-f', type=int, default=-1,\n",
    "                        help='Frequency of taking a snapshot')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=args.gpu,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--out', '-o', default=args.out,\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--resume', '-r', default=args.resume,\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--unit', '-u', dest='n_in', type=int, default=args.n_in,\n",
    "                        help='Number of units')\n",
    "    parser.add_argument('--noplot', dest='plot', action='store_false',\n",
    "                        help='Disable PlotReport extension')\n",
    "    args = parser.parse_args()\n",
    "except:\n",
    "    print('no argsparse')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chainer.datasets import get_cifar10\n",
    "\n",
    "data_train, data_test = get_cifar10()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(data_train.__len__()):\n",
    "    x, y = data_train.__getitem__(i)\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in range(data_test.__len__()):\n",
    "    x, y = data_test.__getitem__(i)\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train = np.swapaxes(x_train*255, 1, 3).astype(np.uint8)\n",
    "x_test = np.swapaxes(x_test*255, 1, 3).astype(np.uint8)\n",
    "\n",
    "x_train.shape, x_train.dtype, x_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self, n_in=32, n_out=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv = L.Convolution2D(None, 16, 3)\n",
    "            self.conv11 = L.Convolution2D(None, 32, 3)\n",
    "            self.conv12 = L.Convolution2D(None, 32, 3)\n",
    "            self.bn1 = L.BatchNormalization(n_in)\n",
    "\n",
    "            self.conv21 = L.Convolution2D(None, 64, 3)\n",
    "            self.conv22 = L.Convolution2D(None, 64, 3)\n",
    "            self.fc = L.Linear(None, n_out)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.conv21(x)\n",
    "        x = self.conv22(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_label = np.unique(y_train).size\n",
    "model = L.Classifier(LeNet(n_label),\n",
    "                    lossfun=F.softmax_cross_entropy,\n",
    "                    accfun=F.accuracy)\n",
    "xp = np\n",
    "if args.gpu >= 0:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "    chainer.cuda.get_device_from_id(args.gpu).use()\n",
    "    model.to_gpu()  # Copy the model to the GPU\n",
    "optimizer = chainer.optimizers.MomentumSGD(args.lr)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "import Augmentor\n",
    "p = Augmentor.Pipeline()\n",
    "p.crop_random(probability=1, percentage_area=0.8)\n",
    "p.resize(probability=1, width=32, height=32)\n",
    "p.flip_left_right(probability=0.5)\n",
    "#p.random_erasing(probability=0.5, rectangle_area=0.2)\n",
    "p.shear(probability=0.3, max_shear_left=2, max_shear_right=2)\n",
    "\n",
    "g = p.keras_generator_from_array(x_train, y_train, batch_size=args.bs)\n",
    "g = ((\n",
    "    xp.array(np.swapaxes((x/255.), 1, 3)).astype(np.float32),\n",
    "    xp.array(y.astype(np.int8))\n",
    "    ) for (x,y) in g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chainer.trainingを使わず，訓練ループをかく\n",
    "chainer.trainingでは，自前のデータのイテレータを使うことができないため．\n",
    "Augmentorを使いたい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練と検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(step=None):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    n_data = 0\n",
    "    n_train = len(y_train)\n",
    "    for _ in range(n_train//args.bs):\n",
    "        xs, ts = next(g) \n",
    "        x = chainer.Variable(xs)\n",
    "        t = chainer.Variable(ts)\n",
    "        optimizer.update(model, x, t)\n",
    "        with chainer.using_config('train', True):\n",
    "            loss = model(x,t)\n",
    "        n_data += len(t.data)\n",
    "        total_loss += float(loss.data) * len(t.data)\n",
    "        total_acc += float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "    loss = total_loss / n_data\n",
    "    acc = total_acc / n_data\n",
    "    print('loss: {:.4f}\\t acc: {:.4f}'.format(loss, acc))\n",
    "\n",
    "def test(step=None):\n",
    "    xs = xp.array(np.swapaxes((x_test), 1, 3)).astype(np.float32)\n",
    "    ts = xp.array(y_test).astype(np.int8)\n",
    "    x = chainer.Variable(xs)\n",
    "    t = chainer.Variable(ts)\n",
    "    loss = model(x,t)\n",
    "\n",
    "    n_data = len(t.data)\n",
    "    total_loss = float(loss.data) * len(t.data)\n",
    "    total_acc = float(model.accuracy.data) * len(t.data)\n",
    "    loss = total_loss / n_data\n",
    "    acc = total_acc / n_data\n",
    "    print('val_loss: {:.4f}\\t val_acc: {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0\n",
      "loss: 1.9503\t acc: 0.2794\n",
      "val_loss: 292.8114\t val_acc: 0.2222\n",
      "step:1\n",
      "loss: 1.6521\t acc: 0.3937\n",
      "val_loss: 259.5572\t val_acc: 0.2265\n",
      "step:2\n",
      "loss: 1.5359\t acc: 0.4428\n",
      "val_loss: 308.9408\t val_acc: 0.2041\n",
      "step:3\n",
      "loss: 1.4658\t acc: 0.4720\n",
      "val_loss: 242.3032\t val_acc: 0.2723\n",
      "step:4\n",
      "loss: 1.4000\t acc: 0.4953\n",
      "val_loss: 194.6915\t val_acc: 0.2527\n",
      "step:5\n",
      "loss: 1.3579\t acc: 0.5157\n",
      "val_loss: 227.5447\t val_acc: 0.2680\n",
      "step:6\n",
      "loss: 1.3127\t acc: 0.5336\n",
      "val_loss: 240.2181\t val_acc: 0.2823\n",
      "step:7\n",
      "loss: 1.2680\t acc: 0.5502\n",
      "val_loss: 274.0311\t val_acc: 0.2436\n",
      "step:8\n",
      "loss: 1.2400\t acc: 0.5629\n",
      "val_loss: 356.4249\t val_acc: 0.2488\n",
      "step:9\n",
      "loss: 1.2174\t acc: 0.5706\n",
      "val_loss: 339.0550\t val_acc: 0.2587\n",
      "step:10\n",
      "loss: 1.1779\t acc: 0.5864\n",
      "val_loss: 204.5528\t val_acc: 0.3245\n",
      "step:11\n",
      "loss: 1.1585\t acc: 0.5931\n",
      "val_loss: 219.2995\t val_acc: 0.2973\n",
      "step:12\n",
      "loss: 1.1268\t acc: 0.6040\n",
      "val_loss: 189.2996\t val_acc: 0.3332\n",
      "step:13\n",
      "loss: 1.1085\t acc: 0.6092\n",
      "val_loss: 187.1102\t val_acc: 0.3460\n",
      "step:14\n",
      "loss: 1.1001\t acc: 0.6129\n",
      "val_loss: 243.2253\t val_acc: 0.2416\n",
      "step:15\n",
      "loss: 1.0846\t acc: 0.6182\n",
      "val_loss: 300.1159\t val_acc: 0.2406\n",
      "step:16\n",
      "loss: 1.0676\t acc: 0.6259\n",
      "val_loss: 250.8678\t val_acc: 0.2844\n",
      "step:17\n",
      "loss: 1.0513\t acc: 0.6340\n",
      "val_loss: 241.7691\t val_acc: 0.2633\n",
      "step:18\n",
      "loss: 1.0392\t acc: 0.6353\n",
      "val_loss: 320.6259\t val_acc: 0.2320\n",
      "step:19\n",
      "loss: 1.0297\t acc: 0.6378\n",
      "val_loss: 180.2671\t val_acc: 0.2872\n",
      "step:20\n",
      "loss: 1.0165\t acc: 0.6412\n",
      "val_loss: 236.4733\t val_acc: 0.2727\n",
      "step:21\n",
      "loss: 1.0046\t acc: 0.6467\n",
      "val_loss: 239.9199\t val_acc: 0.2523\n",
      "step:22\n",
      "loss: 1.0049\t acc: 0.6476\n",
      "val_loss: 321.6301\t val_acc: 0.2278\n",
      "step:23\n",
      "loss: 0.9946\t acc: 0.6523\n",
      "val_loss: 142.9782\t val_acc: 0.3332\n",
      "step:24\n",
      "loss: 0.9688\t acc: 0.6600\n",
      "val_loss: 196.5911\t val_acc: 0.2534\n",
      "step:25\n",
      "loss: 0.9721\t acc: 0.6605\n",
      "val_loss: 219.3225\t val_acc: 0.2671\n",
      "step:26\n",
      "loss: 0.9647\t acc: 0.6590\n",
      "val_loss: 327.8550\t val_acc: 0.2550\n",
      "step:27\n",
      "loss: 0.9535\t acc: 0.6663\n",
      "val_loss: 323.3779\t val_acc: 0.2347\n",
      "step:28\n",
      "loss: 0.9396\t acc: 0.6716\n",
      "val_loss: 203.3059\t val_acc: 0.2368\n",
      "step:29\n",
      "loss: 0.9392\t acc: 0.6718\n",
      "val_loss: 286.1979\t val_acc: 0.2572\n",
      "step:30\n",
      "loss: 0.9235\t acc: 0.6757\n",
      "val_loss: 265.4472\t val_acc: 0.2680\n",
      "step:31\n",
      "loss: 0.9344\t acc: 0.6748\n",
      "val_loss: 288.7394\t val_acc: 0.2596\n",
      "step:32\n",
      "loss: 0.9305\t acc: 0.6753\n",
      "val_loss: 220.8059\t val_acc: 0.2690\n",
      "step:33\n",
      "loss: 0.9099\t acc: 0.6799\n",
      "val_loss: 235.7660\t val_acc: 0.2444\n",
      "step:34\n",
      "loss: 0.9166\t acc: 0.6805\n",
      "val_loss: 217.1578\t val_acc: 0.2441\n",
      "step:35\n",
      "loss: 0.9038\t acc: 0.6834\n",
      "val_loss: 245.9937\t val_acc: 0.2434\n",
      "step:36\n",
      "loss: 0.8997\t acc: 0.6860\n",
      "val_loss: 235.5142\t val_acc: 0.2604\n",
      "step:37\n",
      "loss: 0.9034\t acc: 0.6840\n",
      "val_loss: 226.6016\t val_acc: 0.2353\n",
      "step:38\n",
      "loss: 0.8988\t acc: 0.6852\n",
      "val_loss: 264.7177\t val_acc: 0.2689\n",
      "step:39\n",
      "loss: 0.8943\t acc: 0.6855\n",
      "val_loss: 213.0405\t val_acc: 0.2940\n",
      "step:40\n",
      "loss: 0.8894\t acc: 0.6891\n",
      "val_loss: 203.2431\t val_acc: 0.2793\n",
      "step:41\n",
      "loss: 0.8859\t acc: 0.6900\n",
      "val_loss: 164.1348\t val_acc: 0.3057\n",
      "step:42\n",
      "loss: 0.8758\t acc: 0.6929\n",
      "val_loss: 203.4584\t val_acc: 0.2612\n",
      "step:43\n",
      "loss: 0.8753\t acc: 0.6950\n",
      "val_loss: 221.2648\t val_acc: 0.2703\n",
      "step:44\n",
      "loss: 0.8783\t acc: 0.6940\n",
      "val_loss: 156.4052\t val_acc: 0.2751\n",
      "step:45\n",
      "loss: 0.8675\t acc: 0.6972\n",
      "val_loss: 148.7916\t val_acc: 0.2861\n",
      "step:46\n",
      "loss: 0.8708\t acc: 0.6964\n",
      "val_loss: 175.4374\t val_acc: 0.2517\n",
      "step:47\n",
      "loss: 0.8707\t acc: 0.6966\n",
      "val_loss: 180.1922\t val_acc: 0.2645\n",
      "step:48\n",
      "loss: 0.8719\t acc: 0.6945\n",
      "val_loss: 155.9070\t val_acc: 0.2625\n",
      "step:49\n",
      "loss: 0.8612\t acc: 0.7000\n",
      "val_loss: 146.6897\t val_acc: 0.2524\n",
      "step:50\n",
      "loss: 0.8511\t acc: 0.7042\n",
      "val_loss: 175.1273\t val_acc: 0.2548\n",
      "step:51\n",
      "loss: 0.8522\t acc: 0.7014\n",
      "val_loss: 153.6383\t val_acc: 0.2766\n",
      "step:52\n",
      "loss: 0.8518\t acc: 0.7009\n",
      "val_loss: 173.5845\t val_acc: 0.2944\n",
      "step:53\n",
      "loss: 0.8389\t acc: 0.7089\n",
      "val_loss: 203.4298\t val_acc: 0.2794\n",
      "step:54\n",
      "loss: 0.8506\t acc: 0.7020\n",
      "val_loss: 297.3737\t val_acc: 0.2508\n",
      "step:55\n",
      "loss: 0.8360\t acc: 0.7074\n",
      "val_loss: 189.7239\t val_acc: 0.2448\n",
      "step:56\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-363cff855476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-d85dfc6b42a8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-9088d22d599c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_generator_from_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m g = ((\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36mkeras_generator_from_array\u001b[0;34m(self, images, labels, batch_size, image_data_format)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mrandom_image_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mnumpy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_image_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m_execute_with_array\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mpil_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mnumpy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/Augmentor/Operations.py\u001b[0m in \u001b[0;36mperform_operation\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    972\u001b[0m                                     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                                     \u001b[0mtransform_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                                     Image.BICUBIC)\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_in_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill)\u001b[0m\n\u001b[1;32m   2123\u001b[0m                 \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__transformer\u001b[0;34m(self, box, image, method, data, resample, fill)\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for step in range(args.epoch):\n",
    "        print('step:{}'.format(step))\n",
    "        train(step)\n",
    "        test(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
