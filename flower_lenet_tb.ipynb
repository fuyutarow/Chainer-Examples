{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/fytroo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "from chainer.dataset import convert\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "from chainer.datasets import get_cifar10\n",
    "from chainer.datasets import get_cifar100\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensorboard用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tb_chainer import SummaryWriter, name_scope, within_name_scope\n",
    "try:\n",
    "    writer = SummaryWriter('runs/{}_{}'.format(\n",
    "        __file__, utils.now(isabout=True)))\n",
    "except:\n",
    "    writer = SummaryWriter('runs/'+utils.now(isabout=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no argsparse\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "args = EasyDict({\n",
    "    'bs': 64, \n",
    "    'epoch' : 100,\n",
    "    'lr' : 0.05,\n",
    "    'gpu': 0,\n",
    "    'out': 'result',\n",
    "    'resume': '',\n",
    "    'n_in': 32, \n",
    "})\n",
    "try:\n",
    "    __file__.endswith('py')\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Chainer example: MNIST')\n",
    "    parser.add_argument('--batchsize', '-b', dest='bs', type=int, default=args.bs,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=args.epoch,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--learningrate', '-l', dest='lr', type=float, default=args.lr,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--frequency', '-f', type=int, default=-1,\n",
    "                        help='Frequency of taking a snapshot')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=args.gpu,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--out', '-o', default=args.out,\n",
    "                        help='Directory to output the result')\n",
    "    parser.add_argument('--resume', '-r', default=args.resume,\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--unit', '-u', dest='n_in', type=int, default=args.n_in,\n",
    "                        help='Number of units')\n",
    "    parser.add_argument('--noplot', dest='plot', action='store_false',\n",
    "                        help='Disable PlotReport extension')\n",
    "    args = parser.parse_args()\n",
    "except:\n",
    "    print('no argsparse')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fytroo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0001.png</td>\n",
       "      <td>flower_images/0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0002.png</td>\n",
       "      <td>flower_images/0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0003.png</td>\n",
       "      <td>flower_images/0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>flower_images/0004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0005.png</td>\n",
       "      <td>flower_images/0005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0006.png</td>\n",
       "      <td>flower_images/0006.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0007.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0007.png</td>\n",
       "      <td>flower_images/0007.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0008.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0008.png</td>\n",
       "      <td>flower_images/0008.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0009.png</td>\n",
       "      <td>flower_images/0009.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0010.png</td>\n",
       "      <td>flower_images/0010.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0011.png</td>\n",
       "      <td>flower_images/0011.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0012.png</td>\n",
       "      <td>flower_images/0012.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0013.png</td>\n",
       "      <td>flower_images/0013.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0014.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0014.png</td>\n",
       "      <td>flower_images/0014.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0015.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0015.png</td>\n",
       "      <td>flower_images/0015.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0016.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0016.png</td>\n",
       "      <td>flower_images/0016.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0017.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0017.png</td>\n",
       "      <td>flower_images/0017.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0018.png</td>\n",
       "      <td>flower_images/0018.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0019.png</td>\n",
       "      <td>flower_images/0019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0020.png</td>\n",
       "      <td>flower_images/0020.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0021.png</td>\n",
       "      <td>flower_images/0021.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0022.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0022.png</td>\n",
       "      <td>flower_images/0022.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0023.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0023.png</td>\n",
       "      <td>flower_images/0023.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0024.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0024.png</td>\n",
       "      <td>flower_images/0024.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0025.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0025.png</td>\n",
       "      <td>flower_images/0025.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0026.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0026.png</td>\n",
       "      <td>flower_images/0026.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0027.png</th>\n",
       "      <td>2</td>\n",
       "      <td>0027.png</td>\n",
       "      <td>flower_images/0027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0028.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0028.png</td>\n",
       "      <td>flower_images/0028.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0029.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0029.png</td>\n",
       "      <td>flower_images/0029.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0030.png</td>\n",
       "      <td>flower_images/0030.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0181.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0181.png</td>\n",
       "      <td>flower_images/0181.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0182.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0182.png</td>\n",
       "      <td>flower_images/0182.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0183.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0183.png</td>\n",
       "      <td>flower_images/0183.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0184.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0184.png</td>\n",
       "      <td>flower_images/0184.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0185.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0185.png</td>\n",
       "      <td>flower_images/0185.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0186.png</th>\n",
       "      <td>9</td>\n",
       "      <td>0186.png</td>\n",
       "      <td>flower_images/0186.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0187.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0187.png</td>\n",
       "      <td>flower_images/0187.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0188.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0188.png</td>\n",
       "      <td>flower_images/0188.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0189.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0189.png</td>\n",
       "      <td>flower_images/0189.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0190.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0190.png</td>\n",
       "      <td>flower_images/0190.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0191.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0191.png</td>\n",
       "      <td>flower_images/0191.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0192.png</th>\n",
       "      <td>7</td>\n",
       "      <td>0192.png</td>\n",
       "      <td>flower_images/0192.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0193.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0193.png</td>\n",
       "      <td>flower_images/0193.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0194.png</th>\n",
       "      <td>9</td>\n",
       "      <td>0194.png</td>\n",
       "      <td>flower_images/0194.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0195.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0195.png</td>\n",
       "      <td>flower_images/0195.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0196.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0196.png</td>\n",
       "      <td>flower_images/0196.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0197.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0197.png</td>\n",
       "      <td>flower_images/0197.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0198.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0198.png</td>\n",
       "      <td>flower_images/0198.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0199.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0199.png</td>\n",
       "      <td>flower_images/0199.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0200.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0200.png</td>\n",
       "      <td>flower_images/0200.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0201.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0201.png</td>\n",
       "      <td>flower_images/0201.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0202.png</th>\n",
       "      <td>3</td>\n",
       "      <td>0202.png</td>\n",
       "      <td>flower_images/0202.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0203.png</th>\n",
       "      <td>8</td>\n",
       "      <td>0203.png</td>\n",
       "      <td>flower_images/0203.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0204.png</th>\n",
       "      <td>5</td>\n",
       "      <td>0204.png</td>\n",
       "      <td>flower_images/0204.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0205.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0205.png</td>\n",
       "      <td>flower_images/0205.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0206.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0206.png</td>\n",
       "      <td>flower_images/0206.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0207.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0207.png</td>\n",
       "      <td>flower_images/0207.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0208.png</th>\n",
       "      <td>4</td>\n",
       "      <td>0208.png</td>\n",
       "      <td>flower_images/0208.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0209.png</th>\n",
       "      <td>6</td>\n",
       "      <td>0209.png</td>\n",
       "      <td>flower_images/0209.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0210.png</th>\n",
       "      <td>1</td>\n",
       "      <td>0210.png</td>\n",
       "      <td>flower_images/0210.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label      name                    path\n",
       "file                                             \n",
       "0001.png      0  0001.png  flower_images/0001.png\n",
       "0002.png      0  0002.png  flower_images/0002.png\n",
       "0003.png      2  0003.png  flower_images/0003.png\n",
       "0004.png      0  0004.png  flower_images/0004.png\n",
       "0005.png      0  0005.png  flower_images/0005.png\n",
       "0006.png      1  0006.png  flower_images/0006.png\n",
       "0007.png      6  0007.png  flower_images/0007.png\n",
       "0008.png      0  0008.png  flower_images/0008.png\n",
       "0009.png      0  0009.png  flower_images/0009.png\n",
       "0010.png      0  0010.png  flower_images/0010.png\n",
       "0011.png      0  0011.png  flower_images/0011.png\n",
       "0012.png      0  0012.png  flower_images/0012.png\n",
       "0013.png      0  0013.png  flower_images/0013.png\n",
       "0014.png      7  0014.png  flower_images/0014.png\n",
       "0015.png      7  0015.png  flower_images/0015.png\n",
       "0016.png      1  0016.png  flower_images/0016.png\n",
       "0017.png      0  0017.png  flower_images/0017.png\n",
       "0018.png      0  0018.png  flower_images/0018.png\n",
       "0019.png      6  0019.png  flower_images/0019.png\n",
       "0020.png      0  0020.png  flower_images/0020.png\n",
       "0021.png      2  0021.png  flower_images/0021.png\n",
       "0022.png      4  0022.png  flower_images/0022.png\n",
       "0023.png      7  0023.png  flower_images/0023.png\n",
       "0024.png      4  0024.png  flower_images/0024.png\n",
       "0025.png      5  0025.png  flower_images/0025.png\n",
       "0026.png      6  0026.png  flower_images/0026.png\n",
       "0027.png      2  0027.png  flower_images/0027.png\n",
       "0028.png      5  0028.png  flower_images/0028.png\n",
       "0029.png      6  0029.png  flower_images/0029.png\n",
       "0030.png      6  0030.png  flower_images/0030.png\n",
       "...         ...       ...                     ...\n",
       "0181.png      0  0181.png  flower_images/0181.png\n",
       "0182.png      5  0182.png  flower_images/0182.png\n",
       "0183.png      8  0183.png  flower_images/0183.png\n",
       "0184.png      6  0184.png  flower_images/0184.png\n",
       "0185.png      3  0185.png  flower_images/0185.png\n",
       "0186.png      9  0186.png  flower_images/0186.png\n",
       "0187.png      6  0187.png  flower_images/0187.png\n",
       "0188.png      1  0188.png  flower_images/0188.png\n",
       "0189.png      3  0189.png  flower_images/0189.png\n",
       "0190.png      7  0190.png  flower_images/0190.png\n",
       "0191.png      4  0191.png  flower_images/0191.png\n",
       "0192.png      7  0192.png  flower_images/0192.png\n",
       "0193.png      1  0193.png  flower_images/0193.png\n",
       "0194.png      9  0194.png  flower_images/0194.png\n",
       "0195.png      8  0195.png  flower_images/0195.png\n",
       "0196.png      3  0196.png  flower_images/0196.png\n",
       "0197.png      6  0197.png  flower_images/0197.png\n",
       "0198.png      5  0198.png  flower_images/0198.png\n",
       "0199.png      6  0199.png  flower_images/0199.png\n",
       "0200.png      4  0200.png  flower_images/0200.png\n",
       "0201.png      1  0201.png  flower_images/0201.png\n",
       "0202.png      3  0202.png  flower_images/0202.png\n",
       "0203.png      8  0203.png  flower_images/0203.png\n",
       "0204.png      5  0204.png  flower_images/0204.png\n",
       "0205.png      4  0205.png  flower_images/0205.png\n",
       "0206.png      6  0206.png  flower_images/0206.png\n",
       "0207.png      0  0207.png  flower_images/0207.png\n",
       "0208.png      4  0208.png  flower_images/0208.png\n",
       "0209.png      6  0209.png  flower_images/0209.png\n",
       "0210.png      1  0210.png  flower_images/0210.png\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'flower_images'\n",
    "df  = pd.DataFrame.from_csv(os.path.join(dataset_dir,'flower_labels.csv'))\n",
    "\n",
    "df['name'] = df.index\n",
    "df['path'] = dataset_dir + '/' + df['name']\n",
    "\n",
    "n_label = df.label.drop_duplicates().count()\n",
    "n_label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fromdf(dataframe, resize=(96,96)):\n",
    "    if type(resize) is int:\n",
    "        resize = (resize, resize)\n",
    "    \n",
    "    df = dataframe\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        y = row['label']\n",
    "        f = row['path']\n",
    "\n",
    "        img = Image.open(f).resize(resize, Image.LANCZOS)\n",
    "        img = img.convert('RGB')\n",
    "        x = np.array(img)\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = utils.train_test_split_df(df, test_size=0.1)\n",
    "x_train, y_train = load_fromdf(df_train, resize=args.n_in)\n",
    "x_test, y_test = load_fromdf(df_test, resize=args.n_in)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fire(chainer.Chain):\n",
    "    def __init__(self, n_in=None, n_out=32):\n",
    "        super(Fire, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(n_in, 32, 3)\n",
    "            self.conv2 = L.Convolution2D(None, n_out, 3)\n",
    "            self.bn = L.BatchNormalization(32)\n",
    "            self.bn2 = L.BatchNormalization(32)\n",
    "            self.bn3 = L.BatchNormalization(32)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self, n_in=32, n_out=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 16, 3)\n",
    "            self.conv2 = L.Convolution2D(None, 32, 3)\n",
    "            self.conv3 = L.Convolution2D(None, 64, 3)\n",
    "            self.fc = L.Linear(None, n_out)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.average_pooling_2d(x, ksize=2, stride=2)\n",
    "        x = self.fc(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = L.Classifier(LeNet(args.n_in, n_label),\n",
    "                    lossfun=F.softmax_cross_entropy,\n",
    "                    accfun=F.accuracy)\n",
    "xp = np\n",
    "if args.gpu >= 0:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "    chainer.cuda.get_device_from_id(args.gpu).use()\n",
    "    model.to_gpu()  # Copy the model to the GPU\n",
    "optimizer = chainer.optimizers.MomentumSGD(args.lr)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'random_crop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8cca9ea1e7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip_left_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip_top_bottom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage_area\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_generator_from_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m g = ((\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'random_crop'"
     ]
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "import Augmentor\n",
    "p = Augmentor.Pipeline()\n",
    "p.flip_left_right(probability=0.5)\n",
    "#p.flip_top_bottom(probability=0.5)\n",
    "p.random_crop(probability=1, percentage_area=0.8)\n",
    "#g = p.keras_generator_from_array(x_train, y_train, batch_size=args.bs)\n",
    "g = ((\n",
    "    xp.array(np.swapaxes((x/255.), 1, 3)).astype(np.float32),\n",
    "    xp.array(y.astype(np.int8))\n",
    "    ) for (x,y) in g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chainer.trainingを使わず，訓練ループをかく\n",
    "chainer.trainingでは，自前のデータのイテレータを使うことができないため．\n",
    "Augmentorを使いたい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練と検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(step=None):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    n_data = 0\n",
    "    n_train = len(y_train)\n",
    "    for _ in range(n_train//args.bs):\n",
    "        xs, ts = next(g) \n",
    "        x = chainer.Variable(xs)\n",
    "        t = chainer.Variable(ts)\n",
    "        optimizer.update(model, x, t)\n",
    "        with chainer.using_config('train', True):\n",
    "            loss = model(x,t)\n",
    "        n_data += len(t.data)\n",
    "        total_loss += float(loss.data) * len(t.data)\n",
    "        total_acc += float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "    loss = total_loss / n_data\n",
    "    acc = total_acc / n_data\n",
    "    print('loss: {:.4f}\\t acc: {:.4f}'.format(loss, acc))\n",
    "    writer.add_scalar('loss', loss, step)\n",
    "    writer.add_scalar('accuracy', acc, step)\n",
    "\n",
    "def test(step=None):\n",
    "    xs = xp.array(np.swapaxes((x_test), 1, 3)).astype(np.float32)\n",
    "    ts = xp.array(y_test).astype(np.int8)\n",
    "    x = chainer.Variable(xs)\n",
    "    t = chainer.Variable(ts)\n",
    "    loss = model(x,t)\n",
    "\n",
    "    n_data = len(t.data)\n",
    "    total_loss = float(loss.data) * len(t.data)\n",
    "    total_acc = float(model.accuracy.data) * len(t.data)\n",
    "    loss = total_loss / n_data\n",
    "    acc = total_acc / n_data\n",
    "    print('val_loss: {:.4f}\\t val_acc: {:.4f}'.format(loss, acc))\n",
    "    writer.add_scalar('val_loss', loss, step)\n",
    "    writer.add_scalar('val_accuracy', acc, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0\n",
      "loss: 0.7211\t acc: 0.7604\n",
      "val_loss: 326.0356\t val_acc: 0.6000\n",
      "step:1\n",
      "loss: 0.6597\t acc: 0.7604\n",
      "val_loss: 418.0489\t val_acc: 0.5000\n",
      "step:2\n",
      "loss: 0.7767\t acc: 0.7448\n",
      "val_loss: 392.1396\t val_acc: 0.4000\n",
      "step:3\n",
      "loss: 0.7466\t acc: 0.7240\n",
      "val_loss: 403.4887\t val_acc: 0.6000\n",
      "step:4\n",
      "loss: 0.6762\t acc: 0.7969\n",
      "val_loss: 499.5551\t val_acc: 0.4000\n",
      "step:5\n",
      "loss: 0.7015\t acc: 0.7708\n",
      "val_loss: 496.5107\t val_acc: 0.2000\n",
      "step:6\n",
      "loss: 0.6472\t acc: 0.7396\n",
      "val_loss: 503.8633\t val_acc: 0.4000\n",
      "step:7\n",
      "loss: 0.5936\t acc: 0.8073\n",
      "val_loss: 489.5025\t val_acc: 0.4000\n",
      "step:8\n",
      "loss: 0.6439\t acc: 0.7760\n",
      "val_loss: 454.4442\t val_acc: 0.5000\n",
      "step:9\n",
      "loss: 0.7388\t acc: 0.7396\n",
      "val_loss: 503.1237\t val_acc: 0.3000\n",
      "step:10\n",
      "loss: 0.6994\t acc: 0.7656\n",
      "val_loss: 913.0037\t val_acc: 0.2000\n",
      "step:11\n",
      "loss: 0.6417\t acc: 0.7812\n",
      "val_loss: 879.5249\t val_acc: 0.3000\n",
      "step:12\n",
      "loss: 0.5505\t acc: 0.8438\n",
      "val_loss: 909.2123\t val_acc: 0.4000\n",
      "step:13\n",
      "loss: 0.5953\t acc: 0.8125\n",
      "val_loss: 950.7806\t val_acc: 0.2000\n",
      "step:14\n",
      "loss: 0.7249\t acc: 0.7396\n",
      "val_loss: 995.0512\t val_acc: 0.3000\n",
      "step:15\n",
      "loss: 0.5101\t acc: 0.8385\n",
      "val_loss: 1436.8977\t val_acc: 0.3000\n",
      "step:16\n",
      "loss: 0.5258\t acc: 0.8177\n",
      "val_loss: 1093.9139\t val_acc: 0.3000\n",
      "step:17\n",
      "loss: 0.7005\t acc: 0.8073\n",
      "val_loss: 1057.8430\t val_acc: 0.3000\n",
      "step:18\n",
      "loss: 0.5711\t acc: 0.7969\n",
      "val_loss: 791.9077\t val_acc: 0.3000\n",
      "step:19\n",
      "loss: 0.7542\t acc: 0.7396\n",
      "val_loss: 668.8862\t val_acc: 0.3000\n",
      "step:20\n",
      "loss: 0.7489\t acc: 0.7448\n",
      "val_loss: 414.3528\t val_acc: 0.4000\n",
      "step:21\n",
      "loss: 0.6440\t acc: 0.7708\n",
      "val_loss: 689.2844\t val_acc: 0.3000\n",
      "step:22\n",
      "loss: 0.5863\t acc: 0.7969\n",
      "val_loss: 495.3248\t val_acc: 0.4000\n",
      "step:23\n",
      "loss: 0.5674\t acc: 0.7656\n",
      "val_loss: 418.1634\t val_acc: 0.3000\n",
      "step:24\n",
      "loss: 0.7050\t acc: 0.7292\n",
      "val_loss: 638.5637\t val_acc: 0.3000\n",
      "step:25\n",
      "loss: 0.6171\t acc: 0.7708\n",
      "val_loss: 368.5827\t val_acc: 0.6000\n",
      "step:26\n",
      "loss: 0.5196\t acc: 0.8333\n",
      "val_loss: 412.3235\t val_acc: 0.5000\n",
      "step:27\n",
      "loss: 0.6090\t acc: 0.7969\n",
      "val_loss: 445.6825\t val_acc: 0.5000\n",
      "step:28\n",
      "loss: 0.6287\t acc: 0.7656\n",
      "val_loss: 362.4311\t val_acc: 0.5000\n",
      "step:29\n",
      "loss: 0.5097\t acc: 0.8281\n",
      "val_loss: 442.4309\t val_acc: 0.6000\n",
      "step:30\n",
      "loss: 0.5065\t acc: 0.8490\n",
      "val_loss: 555.6122\t val_acc: 0.6000\n",
      "step:31\n",
      "loss: 0.5971\t acc: 0.7865\n",
      "val_loss: 595.2408\t val_acc: 0.5000\n",
      "step:32\n",
      "loss: 0.5305\t acc: 0.7969\n",
      "val_loss: 492.0408\t val_acc: 0.6000\n",
      "step:33\n",
      "loss: 0.7404\t acc: 0.7448\n",
      "val_loss: 718.9621\t val_acc: 0.3000\n",
      "step:34\n",
      "loss: 0.7125\t acc: 0.7708\n",
      "val_loss: 665.3266\t val_acc: 0.5000\n",
      "step:35\n",
      "loss: 0.5573\t acc: 0.8021\n",
      "val_loss: 642.2792\t val_acc: 0.4000\n",
      "step:36\n",
      "loss: 0.5908\t acc: 0.8073\n",
      "val_loss: 800.4401\t val_acc: 0.4000\n",
      "step:37\n",
      "loss: 0.7263\t acc: 0.7760\n",
      "val_loss: 468.8713\t val_acc: 0.5000\n",
      "step:38\n",
      "loss: 0.5966\t acc: 0.7865\n",
      "val_loss: 289.6692\t val_acc: 0.6000\n",
      "step:39\n",
      "loss: 0.5747\t acc: 0.8229\n",
      "val_loss: 360.6845\t val_acc: 0.6000\n",
      "step:40\n",
      "loss: 0.6191\t acc: 0.7865\n",
      "val_loss: 301.2037\t val_acc: 0.7000\n",
      "step:41\n",
      "loss: 0.6153\t acc: 0.8021\n",
      "val_loss: 222.6701\t val_acc: 0.7000\n",
      "step:42\n",
      "loss: 0.6498\t acc: 0.7500\n",
      "val_loss: 395.0466\t val_acc: 0.6000\n",
      "step:43\n",
      "loss: 0.5020\t acc: 0.8281\n",
      "val_loss: 453.1936\t val_acc: 0.5000\n",
      "step:44\n",
      "loss: 0.5809\t acc: 0.8281\n",
      "val_loss: 452.9768\t val_acc: 0.6000\n",
      "step:45\n",
      "loss: 0.4995\t acc: 0.8646\n",
      "val_loss: 564.4162\t val_acc: 0.5000\n",
      "step:46\n",
      "loss: 0.4761\t acc: 0.8594\n",
      "val_loss: 622.0088\t val_acc: 0.5000\n",
      "step:47\n",
      "loss: 0.5047\t acc: 0.8177\n",
      "val_loss: 604.6321\t val_acc: 0.4000\n",
      "step:48\n",
      "loss: 0.5613\t acc: 0.7917\n",
      "val_loss: 731.5932\t val_acc: 0.3000\n",
      "step:49\n",
      "loss: 0.5028\t acc: 0.8542\n",
      "val_loss: 547.2812\t val_acc: 0.5000\n",
      "step:50\n",
      "loss: 0.4287\t acc: 0.8490\n",
      "val_loss: 353.5956\t val_acc: 0.5000\n",
      "step:51\n",
      "loss: 0.5218\t acc: 0.8281\n",
      "val_loss: 587.0236\t val_acc: 0.3000\n",
      "step:52\n",
      "loss: 0.4495\t acc: 0.8646\n",
      "val_loss: 304.4458\t val_acc: 0.6000\n",
      "step:53\n",
      "loss: 0.5230\t acc: 0.8385\n",
      "val_loss: 432.1116\t val_acc: 0.4000\n",
      "step:54\n",
      "loss: 0.4498\t acc: 0.8490\n",
      "val_loss: 513.4207\t val_acc: 0.3000\n",
      "step:55\n",
      "loss: 0.3341\t acc: 0.8958\n",
      "val_loss: 289.3182\t val_acc: 0.8000\n",
      "step:56\n",
      "loss: 0.4928\t acc: 0.8281\n",
      "val_loss: 349.6350\t val_acc: 0.5000\n",
      "step:57\n",
      "loss: 0.5273\t acc: 0.8333\n",
      "val_loss: 289.8602\t val_acc: 0.7000\n",
      "step:58\n",
      "loss: 0.6466\t acc: 0.7969\n",
      "val_loss: 378.3141\t val_acc: 0.5000\n",
      "step:59\n",
      "loss: 0.6344\t acc: 0.7552\n",
      "val_loss: 683.4611\t val_acc: 0.5000\n",
      "step:60\n",
      "loss: 0.5935\t acc: 0.7865\n",
      "val_loss: 596.9272\t val_acc: 0.5000\n",
      "step:61\n",
      "loss: 0.4183\t acc: 0.8750\n",
      "val_loss: 669.9961\t val_acc: 0.3000\n",
      "step:62\n",
      "loss: 0.4158\t acc: 0.8594\n",
      "val_loss: 977.1471\t val_acc: 0.3000\n",
      "step:63\n",
      "loss: 0.5995\t acc: 0.7969\n",
      "val_loss: 885.2036\t val_acc: 0.3000\n",
      "step:64\n",
      "loss: 0.5644\t acc: 0.8125\n",
      "val_loss: 682.6022\t val_acc: 0.5000\n",
      "step:65\n",
      "loss: 0.5123\t acc: 0.8281\n",
      "val_loss: 1062.7412\t val_acc: 0.3000\n",
      "step:66\n",
      "loss: 0.5877\t acc: 0.7969\n",
      "val_loss: 701.9854\t val_acc: 0.5000\n",
      "step:67\n",
      "loss: 0.5721\t acc: 0.7917\n",
      "val_loss: 423.7006\t val_acc: 0.4000\n",
      "step:68\n",
      "loss: 0.6279\t acc: 0.7760\n",
      "val_loss: 408.8753\t val_acc: 0.5000\n",
      "step:69\n",
      "loss: 0.5777\t acc: 0.7708\n",
      "val_loss: 349.0774\t val_acc: 0.5000\n",
      "step:70\n",
      "loss: 0.6180\t acc: 0.7865\n",
      "val_loss: 378.3288\t val_acc: 0.6000\n",
      "step:71\n",
      "loss: 0.5331\t acc: 0.8177\n",
      "val_loss: 313.1984\t val_acc: 0.6000\n",
      "step:72\n",
      "loss: 0.5262\t acc: 0.8021\n",
      "val_loss: 443.0505\t val_acc: 0.3000\n",
      "step:73\n",
      "loss: 0.5515\t acc: 0.8125\n",
      "val_loss: 854.9164\t val_acc: 0.2000\n",
      "step:74\n",
      "loss: 0.4259\t acc: 0.8490\n",
      "val_loss: 662.5226\t val_acc: 0.3000\n",
      "step:75\n",
      "loss: 0.5210\t acc: 0.8281\n",
      "val_loss: 493.7435\t val_acc: 0.3000\n",
      "step:76\n",
      "loss: 0.5208\t acc: 0.8229\n",
      "val_loss: 510.3322\t val_acc: 0.2000\n",
      "step:77\n",
      "loss: 0.4293\t acc: 0.8594\n",
      "val_loss: 544.8241\t val_acc: 0.4000\n",
      "step:78\n",
      "loss: 0.5281\t acc: 0.8333\n",
      "val_loss: 541.9070\t val_acc: 0.4000\n",
      "step:79\n",
      "loss: 0.4913\t acc: 0.8854\n",
      "val_loss: 631.5085\t val_acc: 0.4000\n",
      "step:80\n",
      "loss: 0.4219\t acc: 0.8698\n",
      "val_loss: 552.8569\t val_acc: 0.5000\n",
      "step:81\n",
      "loss: 0.3823\t acc: 0.8646\n",
      "val_loss: 658.9626\t val_acc: 0.5000\n",
      "step:82\n",
      "loss: 0.3732\t acc: 0.8802\n",
      "val_loss: 525.0207\t val_acc: 0.6000\n",
      "step:83\n",
      "loss: 0.5497\t acc: 0.8385\n",
      "val_loss: 631.8400\t val_acc: 0.5000\n",
      "step:84\n",
      "loss: 0.6422\t acc: 0.7760\n",
      "val_loss: 543.7935\t val_acc: 0.6000\n",
      "step:85\n",
      "loss: 0.7289\t acc: 0.7604\n",
      "val_loss: 793.0368\t val_acc: 0.3000\n",
      "step:86\n",
      "loss: 0.5714\t acc: 0.8073\n",
      "val_loss: 493.8180\t val_acc: 0.4000\n",
      "step:87\n",
      "loss: 0.5627\t acc: 0.7865\n",
      "val_loss: 703.4490\t val_acc: 0.4000\n",
      "step:88\n",
      "loss: 0.6887\t acc: 0.7917\n",
      "val_loss: 788.4525\t val_acc: 0.3000\n",
      "step:89\n",
      "loss: 0.4544\t acc: 0.8438\n",
      "val_loss: 643.0504\t val_acc: 0.3000\n",
      "step:90\n",
      "loss: 0.6721\t acc: 0.7969\n",
      "val_loss: 418.7382\t val_acc: 0.4000\n",
      "step:91\n",
      "loss: 0.6191\t acc: 0.7865\n",
      "val_loss: 586.3390\t val_acc: 0.4000\n",
      "step:92\n",
      "loss: 0.4455\t acc: 0.8438\n",
      "val_loss: 706.9551\t val_acc: 0.4000\n",
      "step:93\n",
      "loss: 0.4519\t acc: 0.8333\n",
      "val_loss: 777.4216\t val_acc: 0.3000\n",
      "step:94\n",
      "loss: 0.6554\t acc: 0.7812\n",
      "val_loss: 748.4665\t val_acc: 0.4000\n",
      "step:95\n",
      "loss: 0.4826\t acc: 0.8385\n",
      "val_loss: 840.7298\t val_acc: 0.3000\n",
      "step:96\n",
      "loss: 0.4627\t acc: 0.8333\n",
      "val_loss: 816.6471\t val_acc: 0.4000\n",
      "step:97\n",
      "loss: 0.5697\t acc: 0.8333\n",
      "val_loss: 729.7841\t val_acc: 0.5000\n",
      "step:98\n",
      "loss: 0.5406\t acc: 0.8177\n",
      "val_loss: 877.8830\t val_acc: 0.4000\n",
      "step:99\n",
      "loss: 0.4497\t acc: 0.8594\n",
      "val_loss: 1429.1643\t val_acc: 0.3000\n",
      "step:100\n",
      "loss: 0.5150\t acc: 0.8333\n",
      "val_loss: 791.5019\t val_acc: 0.6000\n",
      "step:101\n",
      "loss: 0.5219\t acc: 0.8281\n",
      "val_loss: 918.3559\t val_acc: 0.5000\n",
      "step:102\n",
      "loss: 0.5180\t acc: 0.8385\n",
      "val_loss: 810.5601\t val_acc: 0.4000\n",
      "step:103\n",
      "loss: 0.6438\t acc: 0.7500\n",
      "val_loss: 570.1189\t val_acc: 0.5000\n",
      "step:104\n",
      "loss: 0.7223\t acc: 0.7812\n",
      "val_loss: 552.6331\t val_acc: 0.4000\n",
      "step:105\n",
      "loss: 0.5064\t acc: 0.8438\n",
      "val_loss: 662.6478\t val_acc: 0.4000\n",
      "step:106\n",
      "loss: 0.5402\t acc: 0.8229\n",
      "val_loss: 556.9388\t val_acc: 0.6000\n",
      "step:107\n",
      "loss: 0.7329\t acc: 0.7760\n",
      "val_loss: 508.0940\t val_acc: 0.5000\n",
      "step:108\n",
      "loss: 0.4561\t acc: 0.8542\n",
      "val_loss: 452.9146\t val_acc: 0.5000\n",
      "step:109\n",
      "loss: 0.4698\t acc: 0.8490\n",
      "val_loss: 510.4572\t val_acc: 0.5000\n",
      "step:110\n",
      "loss: 0.4949\t acc: 0.8333\n",
      "val_loss: 536.6144\t val_acc: 0.5000\n",
      "step:111\n",
      "loss: 0.4272\t acc: 0.8698\n",
      "val_loss: 557.8668\t val_acc: 0.5000\n",
      "step:112\n",
      "loss: 0.4535\t acc: 0.8490\n",
      "val_loss: 718.9031\t val_acc: 0.6000\n",
      "step:113\n",
      "loss: 0.4821\t acc: 0.8281\n",
      "val_loss: 460.3888\t val_acc: 0.5000\n",
      "step:114\n",
      "loss: 0.4578\t acc: 0.8594\n",
      "val_loss: 519.9638\t val_acc: 0.4000\n",
      "step:115\n",
      "loss: 0.6090\t acc: 0.7344\n",
      "val_loss: 635.6850\t val_acc: 0.4000\n",
      "step:116\n",
      "loss: 0.4699\t acc: 0.8125\n",
      "val_loss: 521.6788\t val_acc: 0.4000\n",
      "step:117\n",
      "loss: 0.6364\t acc: 0.7917\n",
      "val_loss: 778.5397\t val_acc: 0.4000\n",
      "step:118\n",
      "loss: 0.6814\t acc: 0.8125\n",
      "val_loss: 630.6387\t val_acc: 0.5000\n",
      "step:119\n",
      "loss: 0.4966\t acc: 0.8385\n",
      "val_loss: 338.1435\t val_acc: 0.7000\n",
      "step:120\n",
      "loss: 0.6578\t acc: 0.7917\n",
      "val_loss: 581.2531\t val_acc: 0.5000\n",
      "step:121\n",
      "loss: 0.4704\t acc: 0.8854\n",
      "val_loss: 592.0842\t val_acc: 0.5000\n",
      "step:122\n",
      "loss: 0.4729\t acc: 0.8385\n",
      "val_loss: 445.0699\t val_acc: 0.5000\n",
      "step:123\n",
      "loss: 0.4181\t acc: 0.8802\n",
      "val_loss: 466.6255\t val_acc: 0.6000\n",
      "step:124\n",
      "loss: 0.4892\t acc: 0.8490\n",
      "val_loss: 691.5062\t val_acc: 0.4000\n",
      "step:125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3883\t acc: 0.8750\n",
      "val_loss: 622.2659\t val_acc: 0.4000\n",
      "step:126\n",
      "loss: 0.4707\t acc: 0.8177\n",
      "val_loss: 713.8212\t val_acc: 0.4000\n",
      "step:127\n",
      "loss: 0.4338\t acc: 0.8229\n",
      "val_loss: 739.0910\t val_acc: 0.2000\n",
      "step:128\n",
      "loss: 0.4621\t acc: 0.8490\n",
      "val_loss: 773.2643\t val_acc: 0.3000\n",
      "step:129\n",
      "loss: 0.3886\t acc: 0.8750\n",
      "val_loss: 866.2244\t val_acc: 0.3000\n",
      "step:130\n",
      "loss: 0.3700\t acc: 0.8958\n",
      "val_loss: 742.4843\t val_acc: 0.4000\n",
      "step:131\n",
      "loss: 0.3681\t acc: 0.8906\n",
      "val_loss: 565.4011\t val_acc: 0.6000\n",
      "step:132\n",
      "loss: 0.4764\t acc: 0.8542\n",
      "val_loss: 606.8822\t val_acc: 0.5000\n",
      "step:133\n",
      "loss: 0.4233\t acc: 0.8646\n",
      "val_loss: 506.9681\t val_acc: 0.5000\n",
      "step:134\n",
      "loss: 0.4541\t acc: 0.8542\n",
      "val_loss: 654.6484\t val_acc: 0.5000\n",
      "step:135\n",
      "loss: 0.4956\t acc: 0.8750\n",
      "val_loss: 827.4805\t val_acc: 0.4000\n",
      "step:136\n",
      "loss: 0.5257\t acc: 0.8385\n",
      "val_loss: 589.5483\t val_acc: 0.5000\n",
      "step:137\n",
      "loss: 0.4026\t acc: 0.8698\n",
      "val_loss: 554.7137\t val_acc: 0.5000\n",
      "step:138\n",
      "loss: 0.6157\t acc: 0.8125\n",
      "val_loss: 1202.4041\t val_acc: 0.4000\n",
      "step:139\n",
      "loss: 0.6468\t acc: 0.7656\n",
      "val_loss: 545.9405\t val_acc: 0.3000\n",
      "step:140\n",
      "loss: 0.6047\t acc: 0.7760\n",
      "val_loss: 975.2021\t val_acc: 0.1000\n",
      "step:141\n",
      "loss: 0.6459\t acc: 0.7865\n",
      "val_loss: 718.4462\t val_acc: 0.4000\n",
      "step:142\n",
      "loss: 0.4548\t acc: 0.8750\n",
      "val_loss: 451.0088\t val_acc: 0.6000\n",
      "step:143\n",
      "loss: 0.5638\t acc: 0.7760\n",
      "val_loss: 361.5406\t val_acc: 0.6000\n",
      "step:144\n",
      "loss: 0.5088\t acc: 0.8229\n",
      "val_loss: 434.4989\t val_acc: 0.5000\n",
      "step:145\n",
      "loss: 0.5326\t acc: 0.8021\n",
      "val_loss: 631.8315\t val_acc: 0.4000\n",
      "step:146\n",
      "loss: 0.5825\t acc: 0.8229\n",
      "val_loss: 1011.2354\t val_acc: 0.3000\n",
      "step:147\n",
      "loss: 0.5849\t acc: 0.7865\n",
      "val_loss: 818.9147\t val_acc: 0.4000\n",
      "step:148\n",
      "loss: 0.5836\t acc: 0.7760\n",
      "val_loss: 1093.7792\t val_acc: 0.3000\n",
      "step:149\n",
      "loss: 0.5982\t acc: 0.7917\n",
      "val_loss: 997.7646\t val_acc: 0.4000\n",
      "step:150\n",
      "loss: 0.4401\t acc: 0.8021\n",
      "val_loss: 726.4425\t val_acc: 0.5000\n",
      "step:151\n",
      "loss: 0.4571\t acc: 0.8333\n",
      "val_loss: 558.3806\t val_acc: 0.5000\n",
      "step:152\n",
      "loss: 0.3887\t acc: 0.8958\n",
      "val_loss: 610.7914\t val_acc: 0.5000\n",
      "step:153\n",
      "loss: 0.4666\t acc: 0.8594\n",
      "val_loss: 632.6984\t val_acc: 0.5000\n",
      "step:154\n",
      "loss: 0.4501\t acc: 0.8594\n",
      "val_loss: 715.3615\t val_acc: 0.5000\n",
      "step:155\n",
      "loss: 0.4640\t acc: 0.8594\n",
      "val_loss: 913.5649\t val_acc: 0.3000\n",
      "step:156\n",
      "loss: 0.4116\t acc: 0.8333\n",
      "val_loss: 681.6360\t val_acc: 0.6000\n",
      "step:157\n",
      "loss: 0.3695\t acc: 0.8906\n",
      "val_loss: 777.6285\t val_acc: 0.6000\n",
      "step:158\n",
      "loss: 0.3445\t acc: 0.8906\n",
      "val_loss: 1056.1956\t val_acc: 0.2000\n",
      "step:159\n",
      "loss: 0.3801\t acc: 0.8906\n",
      "val_loss: 857.0420\t val_acc: 0.4000\n",
      "step:160\n",
      "loss: 0.4641\t acc: 0.8594\n",
      "val_loss: 547.2646\t val_acc: 0.4000\n",
      "step:161\n",
      "loss: 0.4612\t acc: 0.8281\n",
      "val_loss: 533.3867\t val_acc: 0.3000\n",
      "step:162\n",
      "loss: 0.4343\t acc: 0.8906\n",
      "val_loss: 771.1970\t val_acc: 0.4000\n",
      "step:163\n",
      "loss: 0.3886\t acc: 0.8958\n",
      "val_loss: 706.4153\t val_acc: 0.5000\n",
      "step:164\n",
      "loss: 0.4585\t acc: 0.8698\n",
      "val_loss: 789.4513\t val_acc: 0.4000\n",
      "step:165\n",
      "loss: 0.3685\t acc: 0.8594\n",
      "val_loss: 1048.7148\t val_acc: 0.3000\n",
      "step:166\n",
      "loss: 0.4514\t acc: 0.8646\n",
      "val_loss: 934.4806\t val_acc: 0.3000\n",
      "step:167\n",
      "loss: 0.5089\t acc: 0.8281\n",
      "val_loss: 593.5188\t val_acc: 0.3000\n",
      "step:168\n",
      "loss: 0.3951\t acc: 0.8698\n",
      "val_loss: 796.9534\t val_acc: 0.3000\n",
      "step:169\n",
      "loss: 0.4623\t acc: 0.8490\n",
      "val_loss: 421.1330\t val_acc: 0.5000\n",
      "step:170\n",
      "loss: 0.2951\t acc: 0.9062\n",
      "val_loss: 723.9188\t val_acc: 0.4000\n",
      "step:171\n",
      "loss: 0.5150\t acc: 0.8333\n",
      "val_loss: 627.3228\t val_acc: 0.4000\n",
      "step:172\n",
      "loss: 0.3874\t acc: 0.8594\n",
      "val_loss: 826.3391\t val_acc: 0.4000\n",
      "step:173\n",
      "loss: 0.4418\t acc: 0.8073\n",
      "val_loss: 633.5424\t val_acc: 0.4000\n",
      "step:174\n",
      "loss: 0.4777\t acc: 0.8333\n",
      "val_loss: 656.0629\t val_acc: 0.4000\n",
      "step:175\n",
      "loss: 0.5107\t acc: 0.8229\n",
      "val_loss: 633.3374\t val_acc: 0.5000\n",
      "step:176\n",
      "loss: 0.5053\t acc: 0.8438\n",
      "val_loss: 874.7261\t val_acc: 0.3000\n",
      "step:177\n",
      "loss: 0.4738\t acc: 0.8542\n",
      "val_loss: 743.8176\t val_acc: 0.5000\n",
      "step:178\n",
      "loss: 0.5120\t acc: 0.7969\n",
      "val_loss: 579.4396\t val_acc: 0.5000\n",
      "step:179\n",
      "loss: 0.3589\t acc: 0.8958\n",
      "val_loss: 708.5375\t val_acc: 0.6000\n",
      "step:180\n",
      "loss: 0.5429\t acc: 0.7865\n",
      "val_loss: 487.8894\t val_acc: 0.4000\n",
      "step:181\n",
      "loss: 0.4387\t acc: 0.8281\n",
      "val_loss: 579.5546\t val_acc: 0.5000\n",
      "step:182\n",
      "loss: 0.3238\t acc: 0.9062\n",
      "val_loss: 656.1333\t val_acc: 0.5000\n",
      "step:183\n",
      "loss: 0.5094\t acc: 0.8281\n",
      "val_loss: 1057.5237\t val_acc: 0.4000\n",
      "step:184\n",
      "loss: 0.6116\t acc: 0.7708\n",
      "val_loss: 671.4542\t val_acc: 0.5000\n",
      "step:185\n",
      "loss: 0.6027\t acc: 0.7656\n",
      "val_loss: 680.7226\t val_acc: 0.7000\n",
      "step:186\n",
      "loss: 0.4268\t acc: 0.8438\n",
      "val_loss: 1240.7966\t val_acc: 0.2000\n",
      "step:187\n",
      "loss: 0.5108\t acc: 0.8333\n",
      "val_loss: 938.0000\t val_acc: 0.4000\n",
      "step:188\n",
      "loss: 0.4976\t acc: 0.8542\n",
      "val_loss: 1177.4133\t val_acc: 0.5000\n",
      "step:189\n",
      "loss: 0.5860\t acc: 0.7969\n",
      "val_loss: 968.9832\t val_acc: 0.5000\n",
      "step:190\n",
      "loss: 0.4176\t acc: 0.8281\n",
      "val_loss: 717.2444\t val_acc: 0.5000\n",
      "step:191\n",
      "loss: 0.6954\t acc: 0.7604\n",
      "val_loss: 1417.1547\t val_acc: 0.3000\n",
      "step:192\n",
      "loss: 0.5430\t acc: 0.8177\n",
      "val_loss: 819.4787\t val_acc: 0.4000\n",
      "step:193\n",
      "loss: 0.6431\t acc: 0.8073\n",
      "val_loss: 771.2836\t val_acc: 0.4000\n",
      "step:194\n",
      "loss: 0.5620\t acc: 0.8177\n",
      "val_loss: 812.7258\t val_acc: 0.6000\n",
      "step:195\n",
      "loss: 0.7035\t acc: 0.7865\n",
      "val_loss: 549.5876\t val_acc: 0.5000\n",
      "step:196\n",
      "loss: 0.6207\t acc: 0.8177\n",
      "val_loss: 633.0918\t val_acc: 0.5000\n",
      "step:197\n",
      "loss: 0.3401\t acc: 0.8802\n",
      "val_loss: 692.7586\t val_acc: 0.6000\n",
      "step:198\n",
      "loss: 0.4512\t acc: 0.8594\n",
      "val_loss: 901.0778\t val_acc: 0.5000\n",
      "step:199\n",
      "loss: 0.5440\t acc: 0.8229\n",
      "val_loss: 778.9805\t val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #for step in range(args.epoch):\n",
    "    for step in range(200):\n",
    "        print('step:{}'.format(step))\n",
    "        train(step)\n",
    "        test(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
